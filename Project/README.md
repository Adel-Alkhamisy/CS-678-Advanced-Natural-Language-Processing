# Project for Advanced NLP course
We implement a minimal BERT model with an attention mechanism for question-answering tasks. The dataset used is SD-QA (Faisal et al., 2021) which is built on top of TyDi QA (Clark et al., 2020).
